{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Research Question:\n",
    "    \n",
    "We are interested in clustering reddit subreddit using comment ad submission data to discern connections between subreddits and users. We are hoping to see similar userbases in subreddits we did not expect, or disconnects in userbases between subreddits that appear similar. We want to use a Clustering algorithm to connect subreddits in space, and claculate the distance between subreddits.\n",
    "\n",
    "Data Sources:\n",
    "\n",
    "All our data is coming from reddit. Reddit submission and comment data is publicly accessible, and reddit has a nice API structure. We are using the package PRAW (python reddit api wrapper), which makes the reddit api calls easier to use and python importable. We are attempting build subreddit comment vectors for a large number of reddit users. We would like to create nested dictionaries, the first level key being a reddit user, the second level keys being a subreddit name, and the values being how many time that specific user posted to a specific subreddit. The below script generates this dictionary for us.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import praw\n",
    "import pylab as plt\n",
    "from scipy.stats import ttest_ind\n",
    "\n",
    "reddit = praw.Reddit(client_id='tc_fFbWZrkDSRw',\n",
    "                     client_secret='fTq7nFVzdkCHFZY7jWQvHmkLpwk',\n",
    "                     user_agent='lhimelman',\n",
    "                    username = 'lhimelman',\n",
    "                    password = 'madisonave77')\n",
    "\n",
    "commentFreq = {}\n",
    "\n",
    "#initial subreddits to look at\n",
    "subredditList = [\"funny\",\"AskReddit\",\"todayilearned\",\"science\",\"worldnews\",\"pics\"]\n",
    "\n",
    "\n",
    "for subredditname in subredditList:\n",
    "    subreddit = reddit.subreddit(subredditname)\n",
    "    #grab the hottest post from the subreddit, in our actual data collection we grabbed the top 100\n",
    "    for submission in subreddit.hot(limit=1):\n",
    "        all_comments = submission.comments.list()\n",
    "        for c in all_comments:\n",
    "            try:\n",
    "                print(c.author.name, \":\")\n",
    "                userCFreq = {}\n",
    "                #grab ten comments of each user, in our actual data collection we grabbed all of them\n",
    "                for comment in reddit.redditor(c.author.name).comments.new(limit = 10):\n",
    "                    print(comment.subreddit)\n",
    "                    if comment.subreddit not in userCFreq:\n",
    "                        userCFreq[comment.subreddit] = 1\n",
    "                    else:\n",
    "                        userCFreq[comment.subreddit] += 1\n",
    "                commentFreq[c.author.name] = userCFreq\n",
    "            except:\n",
    "                pass\n",
    "            print(commentFreq)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
